This data entry automation program can scrap a website for relevant information and fills in google forms with the data automatically.

I have taken the case of home rental posts on Zillow website for San Francisco location. Using BeautifulSoup, I have scrapped the details like price, address and link to the post for all the listings and saving it in lists.
I have then made use of Selenium WebDriver to open a previously created google form and fill in the relevant details for each listing and click on the submit button.
This way we can have a spreadsheet with all the relevant information in very less time. We can also modify this code to suit different use cases.
Concepts used: BeautifulSoup, Selenium WebDriver, OOP

![image](https://user-images.githubusercontent.com/25523043/129302697-01c0ffca-da89-4b25-a454-de5c6d66a08a.png)
![image](https://user-images.githubusercontent.com/25523043/129302794-e9ebfadd-d06f-4ee3-9bcd-e153cc10ffce.png)
![image](https://user-images.githubusercontent.com/25523043/129302811-fd6084f8-f5ef-4b68-a470-26b0ccf6b0de.png)
![image](https://user-images.githubusercontent.com/25523043/129302882-715af8fa-bb7b-4ad4-b8f2-e45beafe845c.png)
